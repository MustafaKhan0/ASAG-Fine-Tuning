{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import jsonlines\n",
    "import tiktoken\n",
    "import openai\n",
    "import xmltodict as xmd\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import asyncio\n",
    "from random import randint\n",
    "import importlib\n",
    "import io\n",
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "load_dotenv()\n",
    "import pyperclip\n",
    "import numpy as np\n",
    "\n",
    "# Custom file imports\n",
    "import dataset_util\n",
    "import dataset\n",
    "\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(dataset_util)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_multi_df(dfs : [pd.DataFrame], model : str, prompt_style : str):\n",
    "    avg_way_dict = {\n",
    "        2 : 'binary', \n",
    "        3 : 'weighted',\n",
    "    }\n",
    "    avg_label_dict = {\n",
    "        2 : 'correct', \n",
    "        3 : 1\n",
    "    }\n",
    "    non_label_dict = {\n",
    "        2 : None,\n",
    "        3 : ['correct', 'incorrect', 'contradictory']\n",
    "    }\n",
    "    ground_truths = [x for df in dfs for x in df.prompts['accuracy'].tolist()]\n",
    "    model_predicts = [x for df in dfs for x in df.prompts[f'{prompt_style}_{model}_answer'].tolist()]\n",
    "    print(set(model_predicts) - set(ground_truths))\n",
    "    # return precision_recall_fscore_support(ground_truths, model_predicts, pos_label=avg_label_dict[dfs[0].ways],labels=non_label_dict[dfs[0].ways], average=avg_way_dict[dfs[0].ways], zero_division=np.nan)[2]\n",
    "    return precision_recall_fscore_support(ground_truths, model_predicts, average='weighted')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(os.path.abspath('../'))\n",
    "dataset_path = base_path / 'datasets' \n",
    "semeval_path = dataset_path / 'cleaning' / 'SemEval-2013-task7'\n",
    "semeval3_path = dataset_path / 'semeval-2013-task7' / 'semeval-3way'\n",
    "training_path = semeval3_path / 'training'\n",
    "testing_path = semeval3_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455152\n"
     ]
    }
   ],
   "source": [
    "# DEFINE TESTING SET AND MAKE PROMPTS\n",
    "testing_sets = [\n",
    "    dataset.DataSet(testing_path / '2way' / 'beetle' / 'test-unseen-answers', False, 'beetle', 2, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'beetle' / 'test-unseen-questions', False, 'beetle', 2, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'sciEntsBank' / 'test-unseen-answers', False, 'scientsbank', 2, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'sciEntsBank' / 'test-unseen-questions', False, 'scientsbank', 2, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'sciEntsBank' / 'test-unseen-domains', False, 'scientsbank', 2, test_state='UD'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'beetle' / 'test-unseen-answers', False, 'beetle', 3, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'beetle' / 'test-unseen-questions' , False, 'beetle', 3, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'sciEntsBank' / 'test-unseen-answers', False, 'scientsbank', 3, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'sciEntsBank' / 'test-unseen-questions', False, 'scientsbank', 3, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'sciEntsBank' / 'test-unseen-domains', False, 'scientsbank', 3, test_state='UD'), \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_sets = [\n",
    "    dataset.DataSet(training_path / '2way' / 'beetle', True, 'beetle', 2),\n",
    "    dataset.DataSet(training_path / '2way' / 'sciEntsBank', True, 'sciEntsBank', 2),\n",
    "    dataset.DataSet(training_path / '3way' / 'beetle', True, 'beetle', 2),\n",
    "    dataset.DataSet(training_path / '3way' / 'sciEntsBank', True, 'sciEntsBank', 2),\n",
    "]\n",
    "\n",
    "\n",
    "tokens = []\n",
    "for i, setd in enumerate(testing_sets):\n",
    "    setd.make_prompts('gpt-3.5-turbo', 'kortemeyer', 3, 3, 2,2,1,2)\n",
    "    tokens.append(setd.count_tokens('kortemeyer', 'gpt-3.5-turbo'))\n",
    "for i, setd in enumerate(training_sets):\n",
    "    setd.make_prompts('gpt-3.5-turbo', 'kortemeyer', 3, 3, 2,2,1,2)\n",
    "\n",
    "print((sum(tokens)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.AsyncOpenAI()\n",
    "non_client = openai.OpenAI()\n",
    "\n",
    "three_epoch_id = os.getenv(\"THREE_EPOCH_MODEL\")\n",
    "two_epoch_id = os.getenv(\"TWO_EPOCH_MODEL\")\n",
    "training_file = os.getenv(\"TRAINING_FILE\")\n",
    "valid_file = os.getenv(\"TESTING_FILE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_model(client, model : str, prompt_style: str, rate_limit : int, sets):\n",
    "    for i,ds in enumerate(sets):\n",
    "        print(f'{datetime.datetime.now()}: {i} - Starting')\n",
    "        await ds.gpt_async(client, model, prompt_style, rate_limit)\n",
    "        print(f'{datetime.datetime.now()}: {i} - Completed')\n",
    "        print(f'{datetime.datetime.now()}: Sleeping after {i}')\n",
    "        await asyncio.sleep(65)\n",
    "        print(f'{datetime.datetime.now()}: Awake from sleep after {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate gpt-3.5 turbo\n",
    "\n",
    "await evaluate_model(client, 'gpt-3.5-turbo-1106', 'kortemeyer', 70000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate gpt-4\n",
    "\n",
    "await evaluate_model(client, 'gpt-4', 'kortemeyer', 35000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate three_epoch model\n",
    "\n",
    "await evaluate_model(client, three_epoch_id, 'kortemeyer', 72000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate two_epoch model\n",
    "\n",
    "await evaluate_model(client, two_epoch_id, 'kortemeyer', 60000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload datasets for GPT-4, GPT-3.5, and Finetuned\n",
    "\n",
    "for i, ds in enumerate(testing_sets):\n",
    "    for j, model in enumerate(['gpt-4', 'gpt-3.5-turbo-1106', three_epoch_id, two_epoch_id]):\n",
    "        ds.load_processed(model, 'kortemeyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that regenerated results on specific places where the token limit was surpassed\n",
    "\n",
    "async def revaluate_answer(testing_set : dataset.DataSet, model, prompt_style):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = []\n",
    "    lens = []\n",
    "    \n",
    "    problems = testing_set.prompts[testing_set.prompts[f'{prompt_style}_{model}_answer'].isna()]\n",
    "    print(problems.shape)\n",
    "    questions = problems['question_id'].drop_duplicates()\n",
    "\n",
    "    for quest in questions:\n",
    "\n",
    "        current_problem = problems[problems['question_id'] == quest]\n",
    "        display(HTML(current_problem.isin(problems).to_html()))\n",
    "        lens.append(current_problem.shape[0])\n",
    "\n",
    "        prmptse = list(dataset_util.kortemeyer_prompt(current_problem, testing_set.ways, testing_set.dataset, (-1,-1,-1), (-1,-1,-1), False)[0:2])\n",
    "\n",
    "        tasks.append(asyncio.create_task(testing_set.single_prompt(client, [{'role' : 'system', 'content' : prmptse[0]}, {'role' : 'user', 'content' : prmptse[1]}], model, prompt_style, current_problem['question_id'].iloc[0])))\n",
    "\n",
    "    for task in tasks:\n",
    "        await task\n",
    "    testing_set.prompts.drop(columns=[f'{prompt_style}_{model}_answer', f'{prompt_style}_{model}_correct'], inplace=True)\n",
    "\n",
    "    testing_set.process_responses(model, prompt_style)\n",
    "\n",
    "    new_problems = testing_set.prompts[testing_set.prompts[f'{prompt_style}_{model}_answer'].isna()]\n",
    "    print(new_problems.shape)\n",
    "    return new_problems, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Cell\n",
    "for i, ds in enumerate(testing_sets):\n",
    "    counts = ds.prompts.count()\n",
    "    if len(counts.value_counts()) != 1:\n",
    "            print(f'Dataset {i}, {ds.dataset} {ds.ways}way {ds.test_state} had the following counts:')\n",
    "            print(counts)\n",
    "    for model in ['gpt-4', 'gpt-3.5-turbo-1106', three_epoch_id, two_epoch_id]:\n",
    "        values = ds.prompts[f'kortemeyer_{model}_answer'].value_counts()\n",
    "        if len(values) != ds.ways:\n",
    "            print(f'Dataset {i}, {ds.dataset} {ds.ways}way {ds.test_state}, on {model}, had the following value counts:')\n",
    "            print(values)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientsbank - 2\n",
      "scientsbank - 2\n",
      "beetle - 2\n",
      "beetle - 2\n"
     ]
    }
   ],
   "source": [
    "col = [['SCIENTSBANK'] * 2 + ['BEETLE'] * 2, ['2-way','3-way','2-way','3-way']]\n",
    "inds = ['Questions', 'Student Answers']\n",
    "\n",
    "order_training_sets = [training_sets[1], training_sets[3], training_sets[0], training_sets[2]]\n",
    "\n",
    "for ds in order_training_sets:\n",
    "    print(f'{ds.dataset} - {ds.ways}')\n",
    "\n",
    "def testing_unique_count(ds):\n",
    "    li = []\n",
    "\n",
    "    for qid in ds.prompts['question_id'].unique():\n",
    "        li.append(min(ds.prompts[ds.prompts['question_id'] == qid].shape[0], 15))\n",
    "    return sum(li)\n",
    "\n",
    "data = [\n",
    "    [len(ds.prompts['question_id'].unique()) for ds in order_training_sets],\n",
    "    [testing_unique_count(ds) for ds in order_training_sets],\n",
    "]\n",
    "\n",
    "training_counts = pd.DataFrame(data=data, index=inds, columns=col)\n",
    "training_counts.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hello(ds):\n",
    "    li = []\n",
    "\n",
    "    for qid in ds.prompts['question_id'].unique():\n",
    "        li.append(min(ds.prompts[ds.prompts['question_id'] == qid].shape[0], 15))\n",
    "        v = ds.prompts[ds.prompts['question_id'] == qid].shape[0]\n",
    "        print(v) if v <=16 else '' \n",
    "    return sum(li)\n",
    "hello(training_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [['SCIENTSBANK'] * 6 + ['BEETLE'] * 4, ['2-way'] * 3 + ['3-way'] * 3 + ['2-way'] * 2 + ['3-way'] * 2, ['UA', 'UQ', 'UD'] * 2 + ['UA', 'UQ'] * 2]\n",
    "inds = ['Questions', 'Student Answers']\n",
    "\n",
    "order_testing_sets = testing_sets[2:5] + testing_sets[7:] + testing_sets[:2] + testing_sets[5:7]\n",
    "\n",
    "\n",
    "data = [\n",
    "    [len(ds.prompts['question_id'].unique()) for ds in order_testing_sets],\n",
    "    [ds.prompts.shape[0] for ds in order_testing_sets],\n",
    "]\n",
    "\n",
    "testing_counts = pd.DataFrame(data=data, index=inds, columns=col)\n",
    "testing_counts.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [['SCIENTSBANK'] * 6 + ['BEETLE'] * 4, ['2-way'] * 3 + ['3-way'] * 3 + ['2-way'] * 2 + ['3-way'] * 2, ['UA', 'UQ', 'UD'] * 2 + ['UA', 'UQ'] * 2]\n",
    "inds = ['FT-2_Epochs: GPT-3.5', 'FT-3_Epochs: GPT-3.5',  'GPT-3.5', 'GPT-4']\n",
    "\n",
    "order_testing_sets = testing_sets[2:5] + testing_sets[7:] + testing_sets[:2] + testing_sets[5:7]\n",
    "\n",
    "\n",
    "data = [\n",
    "    [ds.model_f1_score(two_epoch_id, 'kortemeyer') for ds in order_testing_sets],\n",
    "    [ds.model_f1_score(three_epoch_id, 'kortemeyer') for ds in order_testing_sets],\n",
    "    [pd.NA, calc_f1_multi_df(testing_sets[2:5], 'gpt-3.5-turbo-1106', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[7:], 'gpt-3.5-turbo-1106', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[:2], 'gpt-3.5-turbo-1106', 'kortemeyer'), \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[5:7], 'gpt-3.5-turbo-1106', 'kortemeyer'), \n",
    "    ],\n",
    "    [pd.NA, calc_f1_multi_df(testing_sets[2:5], 'gpt-4', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[7:], 'gpt-4', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[:2], 'gpt-4', 'kortemeyer'), \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[5:7], 'gpt-4', 'kortemeyer'), \n",
    "    ],\n",
    "]\n",
    "\n",
    "results = pd.DataFrame(data=data, index=inds, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">SCIENTSBANK</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BEETLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"3\" halign=\"left\">3-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3-way</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT-2_Epochs: GPT-3.5</th>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.736301</td>\n",
       "      <td>0.717856</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.783151</td>\n",
       "      <td>0.707384</td>\n",
       "      <td>0.742991</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.705602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT-3_Epochs: GPT-3.5</th>\n",
       "      <td>0.767635</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.693975</td>\n",
       "      <td>0.765531</td>\n",
       "      <td>0.746544</td>\n",
       "      <td>0.724348</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.648045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.663121</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.644678</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.561480</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.583514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.758691</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.742158</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.681452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SCIENTSBANK                                          \\\n",
       "                           2-way                         3-way             \n",
       "                              UA        UQ        UD        UA        UQ   \n",
       "FT-2_Epochs: GPT-3.5    0.783133  0.736301  0.717856  0.796875  0.783151   \n",
       "FT-3_Epochs: GPT-3.5    0.767635  0.719449  0.693975  0.765531  0.746544   \n",
       "GPT-3.5                     <NA>  0.663121      <NA>      <NA>  0.644678   \n",
       "GPT-4                       <NA>  0.758691      <NA>      <NA>  0.742158   \n",
       "\n",
       "                                  BEETLE                                \n",
       "                                   2-way               3-way            \n",
       "                            UD        UA        UQ        UA        UQ  \n",
       "FT-2_Epochs: GPT-3.5  0.707384  0.742991  0.717029  0.712329  0.705602  \n",
       "FT-3_Epochs: GPT-3.5  0.724348  0.736318  0.631579  0.730769  0.648045  \n",
       "GPT-3.5                   <NA>      <NA>  0.561480      <NA>  0.583514  \n",
       "GPT-4                     <NA>      <NA>  0.644295      <NA>  0.681452  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_pickle('results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">SCIENTSBANK</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BEETLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"3\" halign=\"left\">3-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3-way</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT-2_Epochs: GPT-3.5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT-3_Epochs: GPT-3.5</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.66</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.64</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.56</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.76</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.74</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.64</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SCIENTSBANK                               BEETLE        \\\n",
       "                           2-way             3-way              2-way         \n",
       "                              UA    UQ    UD    UA    UQ    UD     UA    UQ   \n",
       "FT-2_Epochs: GPT-3.5        0.78  0.74  0.72   0.8  0.78  0.71   0.74  0.72   \n",
       "FT-3_Epochs: GPT-3.5        0.77  0.72  0.69  0.77  0.75  0.72   0.74  0.63   \n",
       "GPT-3.5                     <NA>  0.66  <NA>  <NA>  0.64  <NA>   <NA>  0.56   \n",
       "GPT-4                       <NA>  0.76  <NA>  <NA>  0.74  <NA>   <NA>  0.64   \n",
       "\n",
       "                                  \n",
       "                     3-way        \n",
       "                        UA    UQ  \n",
       "FT-2_Epochs: GPT-3.5  0.71  0.71  \n",
       "FT-3_Epochs: GPT-3.5  0.73  0.65  \n",
       "GPT-3.5               <NA>  0.58  \n",
       "GPT-4                 <NA>  0.68  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_results = results.replace(pd.NA, 0).round(2).replace(0, pd.NA)\n",
    "rn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['agregate']\n",
    "inds = ['FT-2_Epochs: GPT-3.5', 'FT-3_Epochs: GPT-3.5',  'GPT-3.5', 'GPT-4']\n",
    "\n",
    "\n",
    "\n",
    "order_testing_sets = testing_sets[2:5] + testing_sets[7:] + testing_sets[:2] + testing_sets[5:7]\n",
    "\n",
    "\n",
    "data = [\n",
    "    calc_f1_multi_df(testing_sets, two_epoch_id, 'kortemeyer'),\n",
    "    calc_f1_multi_df(testing_sets, three_epoch_id, 'kortemeyer'),\n",
    "    calc_f1_multi_df(testing_sets, 'gpt-3.5-turbo-1106', 'kortemeyer'), \n",
    "    calc_f1_multi_df(testing_sets, 'gpt-4', 'kortemeyer'), \n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ag_results = pd.DataFrame(data=data, index=inds, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_results.to_pickle('ag_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [['SCIENTSBANK'] * 6 + ['BEETLE'] * 4, ['2-way'] * 3 + ['3-way'] * 3 + ['2-way'] * 2 + ['3-way'] * 2, ['UA', 'UQ', 'UD'] * 2 + ['UA', 'UQ'] * 2]\n",
    "inds = ['FT-2_Epochs: GPT-3.5', 'FT-3_Epochs: GPT-3.5',  'GPT-3.5', 'GPT-4']\n",
    "\n",
    "\n",
    "\n",
    "order_testing_sets = testing_sets[2:5] + testing_sets[7:] + testing_sets[:2] + testing_sets[5:7]\n",
    "\n",
    "\n",
    "data = [\n",
    "    [ds.model_f1_score(two_epoch_id, 'kortemeyer') for ds in order_testing_sets],\n",
    "    [ds.model_f1_score(three_epoch_id, 'kortemeyer') for ds in order_testing_sets],\n",
    "    [ds.model_f1_score('gpt-3.5-turbo-1106', 'kortemeyer') for ds in order_testing_sets],\n",
    "    [ds.model_f1_score('gpt-4', 'kortemeyer') for ds in order_testing_sets],\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "noag_results = pd.DataFrame(data=data, index=inds, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "noag_results.to_pickle('noag_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_client.fine_tuning.jobs.create(\n",
    "  training_file=training_file, \n",
    "  validation_file=valid_file,\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_msgs = []\n",
    "valid_msgs = []\n",
    "for tset in training_sets:\n",
    "    new_msgs = tset.tune_messages('kortemeyer')\n",
    "    train_msgs = train_msgs + new_msgs[len(new_msgs) // 10:]\n",
    "    valid_msgs = valid_msgs + new_msgs[:len(new_msgs) // 10]\n",
    "\n",
    "with jsonlines.open('semeval-kortemeyer-tuning-v1.jsonl', mode='w') as writer:\n",
    "        writer.write_all(train_msgs)\n",
    "with jsonlines.open('semeval-kortemeyer-valid-v1.jsonl', mode='w') as writer:\n",
    "        writer.write_all(valid_msgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
