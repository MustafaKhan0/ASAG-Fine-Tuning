{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import jsonlines\n",
    "import tiktoken\n",
    "import openai\n",
    "import xmltodict as xmd\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import asyncio\n",
    "from random import randint\n",
    "import importlib\n",
    "import io\n",
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "load_dotenv()\n",
    "import pyperclip\n",
    "import numpy as np\n",
    "\n",
    "# Custom file imports\n",
    "import dataset_util\n",
    "import dataset\n",
    "\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(dataset_util)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_multi_df(dfs : [pd.DataFrame], model : str, prompt_style : str):\n",
    "    avg_way_dict = {\n",
    "        2 : 'binary', \n",
    "        3 : 'weighted',\n",
    "    }\n",
    "    avg_label_dict = {\n",
    "        2 : 'correct', \n",
    "        3 : 1\n",
    "    }\n",
    "    non_label_dict = {\n",
    "        2 : None,\n",
    "        3 : ['correct', 'incorrect', 'contradictory']\n",
    "    }\n",
    "    ground_truths = [x for df in dfs for x in df.prompts['accuracy'].tolist()]\n",
    "    model_predicts = [x for df in dfs for x in df.prompts[f'{prompt_style}_{model}_answer'].tolist()]\n",
    "    print(set(model_predicts) - set(ground_truths))\n",
    "    # return precision_recall_fscore_support(ground_truths, model_predicts, pos_label=avg_label_dict[dfs[0].ways],labels=non_label_dict[dfs[0].ways], average=avg_way_dict[dfs[0].ways], zero_division=np.nan)[2]\n",
    "    return precision_recall_fscore_support(ground_truths, model_predicts, average='weighted')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(os.path.abspath('../'))\n",
    "dataset_path = base_path / 'datasets' \n",
    "semeval_path = dataset_path / 'cleaning' / 'SemEval-2013-task7'\n",
    "semeval3_path = dataset_path / 'semeval-2013-task7' / 'semeval-3way'\n",
    "training_path = semeval3_path / 'training'\n",
    "testing_path = semeval3_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455152\n"
     ]
    }
   ],
   "source": [
    "# DEFINE TESTING SET AND MAKE PROMPTS\n",
    "testing_sets = [\n",
    "    dataset.DataSet(testing_path / '2way' / 'beetle' / 'test-unseen-answers', False, 'beetle', 2, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'beetle' / 'test-unseen-questions', False, 'beetle', 2, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'sciEntsBank' / 'test-unseen-answers', False, 'scientsbank', 2, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'sciEntsBank' / 'test-unseen-questions', False, 'scientsbank', 2, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '2way' / 'sciEntsBank' / 'test-unseen-domains', False, 'scientsbank', 2, test_state='UD'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'beetle' / 'test-unseen-answers', False, 'beetle', 3, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'beetle' / 'test-unseen-questions' , False, 'beetle', 3, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'sciEntsBank' / 'test-unseen-answers', False, 'scientsbank', 3, test_state='UA'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'sciEntsBank' / 'test-unseen-questions', False, 'scientsbank', 3, test_state='UQ'), \n",
    "    dataset.DataSet(testing_path / '3way' / 'sciEntsBank' / 'test-unseen-domains', False, 'scientsbank', 3, test_state='UD'), \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_sets = [\n",
    "    dataset.DataSet(training_path / '2way' / 'beetle', True, 'beetle', 2),\n",
    "    dataset.DataSet(training_path / '2way' / 'sciEntsBank', True, 'sciEntsBank', 2),\n",
    "    dataset.DataSet(training_path / '3way' / 'beetle', True, 'beetle', 2),\n",
    "    dataset.DataSet(training_path / '3way' / 'sciEntsBank', True, 'sciEntsBank', 2),\n",
    "]\n",
    "\n",
    "\n",
    "tokens = []\n",
    "for i, setd in enumerate(testing_sets):\n",
    "    setd.make_prompts('gpt-3.5-turbo', 'kortemeyer', 3, 3, 2,2,1,2)\n",
    "    tokens.append(setd.count_tokens('kortemeyer', 'gpt-3.5-turbo'))\n",
    "\n",
    "print((sum(tokens)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.AsyncOpenAI()\n",
    "non_client = openai.OpenAI()\n",
    "\n",
    "three_epoch_id = os.getenv(\"THREE_EPOCH_MODEL\")\n",
    "two_epoch_id = os.getenv(\"TWO_EPOCH_MODEL\")\n",
    "training_file = os.getenv(\"TRAINING_FILE\")\n",
    "valid_file = os.getenv(\"TESTING_FILE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_model(client, model : str, prompt_style: str, rate_limit : int, sets):\n",
    "    for i,ds in enumerate(sets):\n",
    "        print(f'{datetime.datetime.now()}: {i} - Starting')\n",
    "        await ds.gpt_async(client, model, prompt_style, rate_limit)\n",
    "        print(f'{datetime.datetime.now()}: {i} - Completed')\n",
    "        print(f'{datetime.datetime.now()}: Sleeping after {i}')\n",
    "        await asyncio.sleep(65)\n",
    "        print(f'{datetime.datetime.now()}: Awake from sleep after {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Starting\n",
      "0 - Completed\n",
      "Sleeping after 0\n",
      "Awake from sleep after 0\n",
      "1 - Starting\n",
      "1 - Completed\n",
      "Sleeping after 1\n",
      "Awake from sleep after 1\n",
      "2 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "2 - Completed\n",
      "Sleeping after 2\n",
      "Awake from sleep after 2\n",
      "3 - Starting\n",
      "3 - Completed\n",
      "Sleeping after 3\n",
      "Awake from sleep after 3\n",
      "4 - Starting\n",
      "4 - Completed\n",
      "Sleeping after 4\n",
      "Awake from sleep after 4\n",
      "5 - Starting\n",
      "5 - Completed\n",
      "Sleeping after 5\n",
      "Awake from sleep after 5\n",
      "6 - Starting\n",
      "6 - Completed\n",
      "Sleeping after 6\n",
      "Awake from sleep after 6\n",
      "7 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "7 - Completed\n",
      "Sleeping after 7\n",
      "Awake from sleep after 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "await evaluate_model(client, 'gpt-3.5-turbo-1106', 'kortemeyer', 70000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Starting\n",
      "0 - Completed\n",
      "Sleeping after 0\n",
      "Awake from sleep after 0\n",
      "1 - Starting\n",
      "1 - Completed\n",
      "Sleeping after 1\n",
      "Awake from sleep after 1\n",
      "2 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "2 - Completed\n",
      "Sleeping after 2\n",
      "Awake from sleep after 2\n",
      "3 - Starting\n",
      "3 - Completed\n",
      "Sleeping after 3\n",
      "Awake from sleep after 3\n",
      "4 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "4 - Completed\n",
      "Sleeping after 4\n",
      "Awake from sleep after 4\n",
      "5 - Starting\n",
      "5 - Completed\n",
      "Sleeping after 5\n",
      "Awake from sleep after 5\n",
      "6 - Starting\n",
      "6 - Completed\n",
      "Sleeping after 6\n",
      "Awake from sleep after 6\n",
      "7 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "7 - Completed\n",
      "Sleeping after 7\n",
      "Awake from sleep after 7\n",
      "8 - Starting\n",
      "8 - Completed\n",
      "Sleeping after 8\n",
      "Awake from sleep after 8\n",
      "9 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "9 - Completed\n",
      "Sleeping after 9\n",
      "Awake from sleep after 9\n"
     ]
    }
   ],
   "source": [
    "await evaluate_model(client, 'gpt-4', 'kortemeyer', 35000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-22 19:37:48.271868: 0 - Starting\n",
      "2023-12-22 19:37:54.427153: 0 - Completed\n",
      "2023-12-22 19:37:54.427245: Sleeping after 0\n",
      "2023-12-22 19:38:59.428829: Awake from sleep after 0\n",
      "2023-12-22 19:38:59.429985: 1 - Starting\n",
      "2023-12-22 19:39:44.635762: 1 - Completed\n",
      "2023-12-22 19:39:44.636390: Sleeping after 1\n",
      "2023-12-22 19:40:49.638416: Awake from sleep after 1\n",
      "2023-12-22 19:40:49.639581: 2 - Starting\n",
      "2023-12-22 19:40:52.157553: 2 - Completed\n",
      "2023-12-22 19:40:52.157631: Sleeping after 2\n",
      "2023-12-22 19:41:57.159440: Awake from sleep after 2\n",
      "2023-12-22 19:41:57.161001: 3 - Starting\n",
      "2023-12-22 19:42:10.423803: 3 - Completed\n",
      "2023-12-22 19:42:10.424157: Sleeping after 3\n",
      "2023-12-22 19:43:15.425797: Awake from sleep after 3\n",
      "2023-12-22 19:43:15.426943: 4 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "2023-12-22 19:44:42.050491: 4 - Completed\n",
      "2023-12-22 19:44:42.050601: Sleeping after 4\n",
      "2023-12-22 19:45:47.052922: Awake from sleep after 4\n",
      "2023-12-22 19:45:47.054826: 5 - Starting\n",
      "2023-12-22 19:45:52.718296: 5 - Completed\n",
      "2023-12-22 19:45:52.718383: Sleeping after 5\n",
      "2023-12-22 19:46:57.720780: Awake from sleep after 5\n",
      "2023-12-22 19:46:57.722600: 6 - Starting\n",
      "2023-12-22 19:47:41.839473: 6 - Completed\n",
      "2023-12-22 19:47:41.840090: Sleeping after 6\n",
      "2023-12-22 19:48:46.842955: Awake from sleep after 6\n",
      "2023-12-22 19:48:46.844505: 7 - Starting\n",
      "2023-12-22 19:48:49.341256: 7 - Completed\n",
      "2023-12-22 19:48:49.341347: Sleeping after 7\n",
      "2023-12-22 19:49:54.350089: Awake from sleep after 7\n",
      "2023-12-22 19:49:54.351857: 8 - Starting\n",
      "2023-12-22 19:50:07.988536: 8 - Completed\n",
      "2023-12-22 19:50:07.988658: Sleeping after 8\n",
      "2023-12-22 19:51:12.993304: Awake from sleep after 8\n",
      "2023-12-22 19:51:12.994859: 9 - Starting\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "2023-12-22 19:52:39.034145: 9 - Completed\n",
      "2023-12-22 19:52:39.034317: Sleeping after 9\n",
      "2023-12-22 19:53:44.036096: Awake from sleep after 9\n"
     ]
    }
   ],
   "source": [
    "await evaluate_model(client, three_epoch_id, 'kortemeyer', 72000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 23:07:12.042782: 0 - Starting\n",
      "0 : 3884.79\n",
      "1 : 7700.65\n",
      "2 : 11317.63\n",
      "3 : 15123.32\n",
      "4 : 18334.63\n",
      "5 : 21896.24\n",
      "6 : 25341.460000000003\n",
      "7 : 29045.450000000004\n",
      "8 : 32715.540000000005\n",
      "9 : 36098.61\n",
      "10 : 39775.48\n",
      "11 : 43268.16\n",
      "12 : 46830.9\n",
      "13 : 50499.86\n",
      "14 : 54111.19\n",
      "15 : 57479.57\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "16 : 3420.36\n",
      "17 : 6800.04\n",
      "18 : 10266.73\n",
      "19 : 13863.369999999999\n",
      "20 : 17221.579999999998\n",
      "21 : 20819.35\n",
      "22 : 24130.1\n",
      "23 : 27681.539999999997\n",
      "24 : 31067.999999999996\n",
      "25 : 34695.149999999994\n",
      "26 : 38115.509999999995\n",
      "27 : 41830.799999999996\n",
      "28 : 45073.74999999999\n",
      "29 : 48353.98999999999\n",
      "30 : 51852.31999999999\n",
      "31 : 55606.02999999999\n",
      "32 : 58881.74999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "33 : 3628.2799999999997\n",
      "34 : 7335.66\n",
      "35 : 10967.33\n",
      "36 : 14501.82\n",
      "37 : 17849.86\n",
      "38 : 21419.38\n",
      "39 : 24900.760000000002\n",
      "40 : 28319.99\n",
      "41 : 32675.99\n",
      "42 : 36120.08\n",
      "43 : 39515.58\n",
      "44 : 43183.41\n",
      "45 : 46608.29\n",
      "46 : 50484.04\n",
      "2023-12-31 23:09:37.788079: 0 - Completed\n",
      "2023-12-31 23:09:37.788177: Sleeping after 0\n",
      "2023-12-31 23:10:42.789533: Awake from sleep after 0\n",
      "2023-12-31 23:10:42.790029: 1 - Starting\n",
      "0 : 5163.95\n",
      "1 : 11859.05\n",
      "2 : 20468.37\n",
      "3 : 27535.239999999998\n",
      "4 : 34719.63\n",
      "5 : 43090.52\n",
      "6 : 49638.719999999994\n",
      "7 : 55077.259999999995\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "8 : 6568.539999999999\n",
      "2023-12-31 23:12:17.139848: 1 - Completed\n",
      "2023-12-31 23:12:17.140017: Sleeping after 1\n",
      "2023-12-31 23:13:22.141518: Awake from sleep after 1\n",
      "2023-12-31 23:13:22.141982: 2 - Starting\n",
      "0 : 3273.46\n",
      "1 : 6622.63\n",
      "2 : 9983.1\n",
      "3 : 13314.19\n",
      "4 : 16689.35\n",
      "5 : 20049.82\n",
      "6 : 23501.82\n",
      "7 : 26840.82\n",
      "8 : 30123.32\n",
      "9 : 33437.46\n",
      "10 : 36738.04\n",
      "11 : 39983.25\n",
      "12 : 43280.44\n",
      "13 : 46646.560000000005\n",
      "14 : 49920.020000000004\n",
      "15 : 53339.25000000001\n",
      "16 : 56609.32000000001\n",
      "17 : 59914.420000000006\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "18 : 3352.56\n",
      "19 : 6633.93\n",
      "20 : 9946.94\n",
      "21 : 13369.560000000001\n",
      "22 : 16673.530000000002\n",
      "23 : 19959.420000000002\n",
      "24 : 23323.280000000002\n",
      "25 : 26610.300000000003\n",
      "26 : 29906.360000000004\n",
      "27 : 33291.69\n",
      "28 : 36558.37\n",
      "29 : 39875.9\n",
      "30 : 43274.79\n",
      "31 : 46601.36\n",
      "32 : 49884.99\n",
      "33 : 53152.799999999996\n",
      "34 : 56494.06\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "35 : 3575.17\n",
      "36 : 7046.38\n",
      "37 : 10350.35\n",
      "38 : 13722.12\n",
      "39 : 17031.74\n",
      "40 : 20305.2\n",
      "41 : 23672.45\n",
      "42 : 26933.48\n",
      "43 : 30230.67\n",
      "44 : 33479.27\n",
      "45 : 36778.719999999994\n",
      "46 : 40072.52\n",
      "47 : 43541.469999999994\n",
      "48 : 46816.06\n",
      "49 : 50081.61\n",
      "50 : 53521.18\n",
      "51 : 56866.96\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "52 : 3328.83\n",
      "53 : 6571.78\n",
      "54 : 9816.99\n",
      "55 : 13218.14\n",
      "56 : 16534.54\n",
      "57 : 19935.690000000002\n",
      "58 : 23246.440000000002\n",
      "59 : 26551.54\n",
      "60 : 29843.08\n",
      "61 : 33269.090000000004\n",
      "62 : 36671.37\n",
      "63 : 39973.08\n",
      "64 : 43284.96\n",
      "65 : 46577.63\n",
      "66 : 49826.229999999996\n",
      "67 : 53125.67999999999\n",
      "68 : 56374.27999999999\n",
      "69 : 59686.15999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "70 : 3416.97\n",
      "71 : 6727.719999999999\n",
      "72 : 10089.32\n",
      "73 : 13487.08\n",
      "74 : 16780.88\n",
      "75 : 20061.120000000003\n",
      "76 : 23324.410000000003\n",
      "77 : 26644.200000000004\n",
      "78 : 29889.410000000003\n",
      "79 : 33194.51\n",
      "80 : 36605.83\n",
      "81 : 39856.69\n",
      "82 : 43205.86\n",
      "83 : 46484.97\n",
      "84 : 49733.57\n",
      "85 : 53028.5\n",
      "86 : 56296.31\n",
      "87 : 59585.59\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "88 : 3279.11\n",
      "89 : 6656.530000000001\n",
      "90 : 10049.77\n",
      "91 : 13457.7\n",
      "92 : 16715.34\n",
      "93 : 19950.38\n",
      "94 : 23354.920000000002\n",
      "95 : 26766.24\n",
      "96 : 30017.100000000002\n",
      "97 : 33270.22\n",
      "98 : 36548.200000000004\n",
      "99 : 39835.22\n",
      "100 : 43139.19\n",
      "101 : 46425.08\n",
      "102 : 49781.03\n",
      "103 : 53062.4\n",
      "104 : 56301.96\n",
      "105 : 59586.72\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "106 : 3348.04\n",
      "107 : 6610.2\n",
      "108 : 9883.66\n",
      "109 : 13137.91\n",
      "110 : 16474.65\n",
      "111 : 19803.480000000003\n",
      "112 : 23071.290000000005\n",
      "113 : 26374.130000000005\n",
      "114 : 29721.040000000005\n",
      "115 : 33037.44\n",
      "116 : 36339.15\n",
      "117 : 39736.91\n",
      "118 : 43055.57000000001\n",
      "119 : 46430.73000000001\n",
      "120 : 49909.85000000001\n",
      "121 : 53175.400000000016\n",
      "122 : 56578.81000000001\n",
      "123 : 59931.37000000001\n",
      "Rate limit reached, sleeping for a bit :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-50' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76726, Requested 4096. Please try again in 616ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76726, Requested 4096. Please try again in 616ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-49' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75981, Requested 4096. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75981, Requested 4096. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-48' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76734, Requested 4096. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76734, Requested 4096. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-46' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76802, Requested 4096. Please try again in 673ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76802, Requested 4096. Please try again in 673ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-45' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75978, Requested 4096. Please try again in 55ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75978, Requested 4096. Please try again in 55ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-40' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76788, Requested 4096. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76788, Requested 4096. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-39' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75980, Requested 4096. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75980, Requested 4096. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-38' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75966, Requested 4096. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75966, Requested 4096. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-36' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75955, Requested 4096. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75955, Requested 4096. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-32' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76789, Requested 4096. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76789, Requested 4096. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-28' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75971, Requested 4096. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75971, Requested 4096. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-26' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75991, Requested 4096. Please try again in 65ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 75991, Requested 4096. Please try again in 65ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-21' coro=<DataSet.single_prompt() done, defined at /Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py:73> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76797, Requested 4096. Please try again in 669ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mustafakhan/Library/Mobile Documents/com~apple~CloudDocs/My Stuff/Tech Shtuff/Code/OSR/Project1-ASAG/code/dataset.py\", line 74, in single_prompt\n",
      "    completion = await client.chat.completions.create(messages=messages, model=model, max_tokens=2000)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1482, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1314, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1364, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mustafakhan/opt/anaconda3/envs/ASAG_1/lib/python3.11/site-packages/openai/_base_client.py\", line 1326, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-1106-shared in organization org-kNWrlbE4H3rBX7IlaZ2VXPbH on tokens_usage_based per min: Limit 80000, Used 76797, Requested 4096. Please try again in 669ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up and awake\n",
      "124 : 3462.17\n",
      "125 : 6925.47\n",
      "126 : 10340.18\n",
      "127 : 13791.05\n",
      "128 : 17080.329999999998\n",
      "129 : 20398.989999999998\n",
      "130 : 23785.449999999997\n",
      "131 : 27169.649999999998\n",
      "132 : 30405.82\n",
      "133 : 33750.47\n",
      "134 : 37046.53\n",
      "2023-12-31 23:21:33.621185: 2 - Completed\n",
      "2023-12-31 23:21:33.621275: Sleeping after 2\n",
      "2023-12-31 23:22:38.622770: Awake from sleep after 2\n",
      "2023-12-31 23:22:38.623173: 3 - Starting\n",
      "0 : 4179.719999999999\n",
      "1 : 8321.02\n",
      "2 : 12943.7\n",
      "3 : 17221.73\n",
      "4 : 21618.41\n",
      "5 : 25706.6\n",
      "6 : 30058.079999999998\n",
      "7 : 34702.229999999996\n",
      "8 : 39792.729999999996\n",
      "9 : 43980.35999999999\n",
      "10 : 50251.70999999999\n",
      "11 : 54656.29999999999\n",
      "12 : 59191.96999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "13 : 4265.6\n",
      "14 : 8626.12\n",
      "2023-12-31 23:23:53.343926: 3 - Completed\n",
      "2023-12-31 23:23:53.344072: Sleeping after 3\n",
      "2023-12-31 23:24:58.345473: Awake from sleep after 3\n",
      "2023-12-31 23:24:58.345802: 4 - Starting\n",
      "0 : 5762.85\n",
      "1 : 11705.369999999999\n",
      "2 : 19399.39\n",
      "3 : 25640.23\n",
      "4 : 31170.3\n",
      "5 : 37153.5\n",
      "6 : 42430.45\n",
      "7 : 49144.759999999995\n",
      "8 : 54119.99999999999\n",
      "9 : 59452.31999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "10 : 6087.16\n",
      "11 : 11683.9\n",
      "12 : 18730.43\n",
      "13 : 24333.95\n",
      "14 : 30188.33\n",
      "15 : 35764.73\n",
      "16 : 42126.48\n",
      "17 : 47698.36\n",
      "18 : 52835.19\n",
      "19 : 58801.44\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "20 : 5688.2699999999995\n",
      "21 : 11151.669999999998\n",
      "22 : 16374.379999999997\n",
      "23 : 21673.929999999997\n",
      "24 : 27167.839999999997\n",
      "25 : 33205.28\n",
      "26 : 38727.44\n",
      "27 : 44170.5\n",
      "28 : 49482.479999999996\n",
      "29 : 55916.549999999996\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "30 : 6229.539999999999\n",
      "31 : 12742.71\n",
      "32 : 17800.44\n",
      "33 : 24277.449999999997\n",
      "34 : 29406.369999999995\n",
      "35 : 35524.03999999999\n",
      "36 : 40863.13999999999\n",
      "37 : 46447.44999999999\n",
      "38 : 51580.88999999999\n",
      "39 : 56826.19999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "40 : 6377.57\n",
      "41 : 11561.86\n",
      "42 : 16830.9\n",
      "43 : 22518.04\n",
      "44 : 27731.71\n",
      "45 : 34038.09\n",
      "2023-12-31 23:29:54.741889: 4 - Completed\n",
      "2023-12-31 23:29:54.741993: Sleeping after 4\n",
      "2023-12-31 23:30:59.744506: Awake from sleep after 4\n",
      "2023-12-31 23:30:59.744942: 5 - Starting\n",
      "0 : 3906.2599999999998\n",
      "1 : 7743.59\n",
      "2 : 11382.04\n",
      "3 : 15209.2\n",
      "4 : 18441.98\n",
      "5 : 22025.059999999998\n",
      "6 : 25491.749999999996\n",
      "7 : 29217.209999999995\n",
      "8 : 32908.77\n",
      "9 : 36313.31\n",
      "10 : 40011.649999999994\n",
      "11 : 43525.799999999996\n",
      "12 : 47110.009999999995\n",
      "13 : 50800.439999999995\n",
      "14 : 54433.24\n",
      "15 : 57823.09\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "16 : 3441.83\n",
      "17 : 6842.98\n",
      "18 : 10331.14\n",
      "19 : 13949.25\n",
      "20 : 17328.93\n",
      "21 : 20948.17\n",
      "22 : 24280.39\n",
      "23 : 27853.3\n",
      "24 : 31261.23\n",
      "25 : 34909.85\n",
      "26 : 38351.68\n",
      "27 : 42088.44\n",
      "28 : 45352.86\n",
      "29 : 48654.57\n",
      "30 : 52174.37\n",
      "31 : 55949.55\n",
      "32 : 59246.740000000005\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "33 : 3649.75\n",
      "34 : 7378.6\n",
      "35 : 11031.74\n",
      "36 : 14587.7\n",
      "37 : 17957.21\n",
      "38 : 21548.199999999997\n",
      "39 : 25051.049999999996\n",
      "40 : 28491.749999999996\n",
      "41 : 32869.219999999994\n",
      "42 : 36334.77999999999\n",
      "43 : 39751.74999999999\n",
      "44 : 43441.049999999996\n",
      "45 : 46887.399999999994\n",
      "46 : 50784.619999999995\n",
      "2023-12-31 23:33:26.238839: 5 - Completed\n",
      "2023-12-31 23:33:26.238916: Sleeping after 5\n",
      "2023-12-31 23:34:31.241412: Awake from sleep after 5\n",
      "2023-12-31 23:34:31.241819: 6 - Starting\n",
      "0 : 5185.42\n",
      "1 : 11901.99\n",
      "2 : 20532.78\n",
      "3 : 27621.12\n",
      "4 : 34826.979999999996\n",
      "5 : 43219.34\n",
      "6 : 49789.009999999995\n",
      "7 : 55249.02\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "8 : 6590.01\n",
      "2023-12-31 23:36:05.070244: 6 - Completed\n",
      "2023-12-31 23:36:05.070392: Sleeping after 6\n",
      "2023-12-31 23:37:10.072898: Awake from sleep after 6\n",
      "2023-12-31 23:37:10.073303: 7 - Starting\n",
      "0 : 3294.93\n",
      "1 : 6665.57\n",
      "2 : 10047.51\n",
      "3 : 13400.07\n",
      "4 : 16796.7\n",
      "5 : 20178.64\n",
      "6 : 23652.11\n",
      "7 : 27012.58\n",
      "8 : 30316.550000000003\n",
      "9 : 33652.16\n",
      "10 : 36974.21000000001\n",
      "11 : 40240.89000000001\n",
      "12 : 43559.55\n",
      "13 : 46947.14\n",
      "14 : 50242.07\n",
      "15 : 53682.77\n",
      "16 : 56974.31\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "17 : 3326.57\n",
      "18 : 6700.6\n",
      "19 : 10003.44\n",
      "20 : 13337.92\n",
      "21 : 16782.010000000002\n",
      "22 : 20107.45\n",
      "23 : 23414.81\n",
      "24 : 26800.14\n",
      "25 : 30108.629999999997\n",
      "26 : 33426.159999999996\n",
      "27 : 36832.96\n",
      "28 : 40121.11\n",
      "29 : 43460.11\n",
      "30 : 46880.47\n",
      "31 : 50228.51\n",
      "32 : 53533.61\n",
      "33 : 56822.89\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "34 : 3362.73\n",
      "35 : 6959.37\n",
      "36 : 10452.05\n",
      "37 : 13777.49\n",
      "38 : 17170.73\n",
      "39 : 20501.82\n",
      "40 : 23796.75\n",
      "41 : 27185.47\n",
      "42 : 30467.97\n",
      "43 : 33786.630000000005\n",
      "44 : 37056.700000000004\n",
      "45 : 40377.62\n",
      "46 : 43692.89\n",
      "47 : 47183.31\n",
      "48 : 50479.369999999995\n",
      "49 : 53766.38999999999\n",
      "50 : 57227.42999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "51 : 3367.25\n",
      "52 : 6717.55\n",
      "53 : 9981.970000000001\n",
      "54 : 13248.650000000001\n",
      "55 : 16671.27\n",
      "56 : 20009.14\n",
      "57 : 23431.76\n",
      "58 : 26763.98\n",
      "59 : 30090.55\n",
      "60 : 33403.56\n",
      "61 : 36851.04\n",
      "62 : 40274.79\n",
      "63 : 43597.97\n",
      "64 : 46931.32\n",
      "65 : 50245.46\n",
      "66 : 53515.53\n",
      "67 : 56836.45\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "68 : 3270.07\n",
      "69 : 6603.42\n",
      "70 : 10041.86\n",
      "71 : 13374.08\n",
      "72 : 16757.15\n",
      "73 : 20176.38\n",
      "74 : 23491.65\n",
      "75 : 26793.36\n",
      "76 : 30078.120000000003\n",
      "77 : 33419.380000000005\n",
      "78 : 36686.060000000005\n",
      "79 : 40012.630000000005\n",
      "80 : 43445.420000000006\n",
      "81 : 46717.75000000001\n",
      "82 : 50088.39000000001\n",
      "83 : 53388.97000000001\n",
      "84 : 56659.04000000001\n",
      "85 : 59975.44000000001\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "86 : 3289.2799999999997\n",
      "87 : 6600.03\n",
      "88 : 9900.61\n",
      "89 : 13299.5\n",
      "90 : 16714.21\n",
      "91 : 20143.61\n",
      "92 : 23422.72\n",
      "93 : 26679.230000000003\n",
      "94 : 30105.24\n",
      "95 : 33538.03\n",
      "96 : 36810.36\n",
      "97 : 40084.95\n",
      "98 : 43384.399999999994\n",
      "99 : 46692.88999999999\n",
      "100 : 50018.329999999994\n",
      "101 : 53325.689999999995\n",
      "102 : 56703.10999999999\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "103 : 3302.84\n",
      "104 : 6563.87\n",
      "105 : 9870.1\n",
      "106 : 13239.61\n",
      "107 : 16523.24\n",
      "108 : 19818.170000000002\n",
      "109 : 23093.890000000003\n",
      "110 : 26452.100000000002\n",
      "111 : 29802.4\n",
      "112 : 33091.68\n",
      "113 : 36415.99\n",
      "114 : 39784.369999999995\n",
      "115 : 43122.24\n",
      "116 : 46445.42\n",
      "117 : 49864.65\n",
      "118 : 53204.78\n",
      "119 : 56601.409999999996\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "120 : 3500.59\n",
      "121 : 6787.610000000001\n",
      "122 : 10212.490000000002\n",
      "123 : 13586.52\n",
      "124 : 17070.16\n",
      "125 : 20554.93\n",
      "126 : 23991.11\n",
      "127 : 27463.45\n",
      "128 : 30774.2\n",
      "129 : 34114.33\n",
      "130 : 37522.26\n",
      "131 : 40927.93\n",
      "132 : 44185.57\n",
      "133 : 47551.69\n",
      "134 : 50869.22\n",
      "2023-12-31 23:45:21.558697: 7 - Completed\n",
      "2023-12-31 23:45:21.558784: Sleeping after 7\n",
      "2023-12-31 23:50:51.025613: Awake from sleep after 7\n",
      "2023-12-31 23:50:51.026009: 8 - Starting\n",
      "0 : 4201.19\n",
      "1 : 8363.96\n",
      "2 : 13008.109999999999\n",
      "3 : 17307.61\n",
      "4 : 21725.760000000002\n",
      "5 : 25835.420000000002\n",
      "6 : 30208.370000000003\n",
      "7 : 34873.990000000005\n",
      "8 : 39985.96000000001\n",
      "9 : 44195.060000000005\n",
      "10 : 50487.880000000005\n",
      "11 : 54913.94\n",
      "12 : 59471.08\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "13 : 4287.07\n",
      "14 : 8669.06\n",
      "2023-12-31 23:56:52.207659: 8 - Completed\n",
      "2023-12-31 23:56:52.207786: Sleeping after 8\n",
      "2023-12-31 23:58:16.006827: Awake from sleep after 8\n",
      "2023-12-31 23:58:16.007103: 9 - Starting\n",
      "0 : 5784.32\n",
      "1 : 11748.31\n",
      "2 : 19463.8\n",
      "3 : 25726.11\n",
      "4 : 31277.65\n",
      "5 : 37282.32\n",
      "6 : 42580.74\n",
      "7 : 49316.52\n",
      "8 : 54313.229999999996\n",
      "9 : 59667.02\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "10 : 6108.629999999999\n",
      "11 : 11726.839999999998\n",
      "12 : 18794.839999999997\n",
      "13 : 24419.829999999994\n",
      "14 : 30295.679999999993\n",
      "15 : 35893.549999999996\n",
      "16 : 42276.77\n",
      "17 : 47870.119999999995\n",
      "18 : 53028.42\n",
      "19 : 59016.14\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "20 : 5709.74\n",
      "21 : 11194.61\n",
      "22 : 16438.79\n",
      "23 : 21759.81\n",
      "24 : 27275.190000000002\n",
      "25 : 33334.100000000006\n",
      "26 : 38877.73\n",
      "27 : 44342.26\n",
      "28 : 49675.71\n",
      "29 : 56131.25\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "30 : 6251.01\n",
      "31 : 12785.65\n",
      "32 : 17864.85\n",
      "33 : 24363.329999999998\n",
      "34 : 29513.719999999998\n",
      "35 : 35652.86\n",
      "36 : 41013.43\n",
      "37 : 46619.21\n",
      "38 : 51774.119999999995\n",
      "39 : 57040.899999999994\n",
      "Rate limit reached, sleeping for a bit :)\n",
      "Up and awake\n",
      "40 : 6399.039999999999\n",
      "41 : 11604.8\n",
      "42 : 16895.309999999998\n",
      "43 : 22603.92\n",
      "44 : 27839.059999999998\n",
      "45 : 34166.909999999996\n",
      "2024-01-01 00:04:57.370094: 9 - Completed\n",
      "2024-01-01 00:04:57.370177: Sleeping after 9\n",
      "2024-01-01 00:06:04.473246: Awake from sleep after 9\n"
     ]
    }
   ],
   "source": [
    "# Evaluate GPT-3.5, Fine tuned, 2 epochs\n",
    "\n",
    "await evaluate_model(client, two_epoch_id, 'kortemeyer', 60000, testing_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload datasets for GPT-4, GPT-3.5, and Finetuned\n",
    "\n",
    "for i, ds in enumerate(testing_sets):\n",
    "    for j, model in enumerate(['gpt-4', 'gpt-3.5-turbo-1106', three_epoch_id, two_epoch_id]):\n",
    "        ds.load_processed(model, 'kortemeyer')\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that regenerated results on specific places where the token limit was surpassed\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "async def revaluate_answer(testing_set : dataset.DataSet, model, prompt_style):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = []\n",
    "    lens = []\n",
    "    \n",
    "    problems = testing_set.prompts[testing_set.prompts[f'{prompt_style}_{model}_answer'].isna()]\n",
    "    print(problems.shape)\n",
    "    questions = problems['question_id'].drop_duplicates()\n",
    "\n",
    "    for quest in questions:\n",
    "\n",
    "        current_problem = problems[problems['question_id'] == quest]\n",
    "        display(HTML(current_problem.isin(problems).to_html()))\n",
    "        lens.append(current_problem.shape[0])\n",
    "\n",
    "        prmptse = list(dataset_util.kortemeyer_prompt(current_problem, testing_set.ways, testing_set.dataset, (-1,-1,-1), (-1,-1,-1), False)[0:2])\n",
    "\n",
    "        tasks.append(asyncio.create_task(testing_set.single_prompt(client, [{'role' : 'system', 'content' : prmptse[0]}, {'role' : 'user', 'content' : prmptse[1]}], model, prompt_style, current_problem['question_id'].iloc[0])))\n",
    "\n",
    "    for task in tasks:\n",
    "        await task\n",
    "    testing_set.prompts.drop(columns=[f'{prompt_style}_{model}_answer', f'{prompt_style}_{model}_correct'], inplace=True)\n",
    "\n",
    "    testing_set.process_responses(model, prompt_style)\n",
    "\n",
    "    new_problems = testing_set.prompts[testing_set.prompts[f'{prompt_style}_{model}_answer'].isna()]\n",
    "    print(new_problems.shape)\n",
    "    return new_problems, lens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 24)\n"
     ]
    }
   ],
   "source": [
    "print(testing_sets[1].prompts.shape)\n",
    "hielo=testing_sets[1].prompts.duplicated(subset='answer_id', keep=False)\n",
    "\n",
    "testing_sets[1].prompts[hielo]\n",
    "\n",
    "\n",
    "\n",
    "# testing_sets[1].prompts[576:583][['answer_id', 'kortemeyer_gpt-4_completion', 'kortemeyer_gpt-4_answer', 'kortemeyer_gpt-4_correct']]\n",
    "testing_sets[6].prompts = testing_sets[6].prompts.drop(index=[578]).reset_index()\n",
    "testing_sets[1].prompts = testing_sets[1].prompts.drop(index=[579]).reset_index()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Cell\n",
    "for i, ds in enumerate(testing_sets):\n",
    "    counts = ds.prompts.count()\n",
    "    if len(counts.value_counts()) != 1:\n",
    "            print(f'Dataset {i}, {ds.dataset} {ds.ways}way {ds.test_state} had the following counts:')\n",
    "            print(counts)\n",
    "    for model in ['gpt-4', 'gpt-3.5-turbo-1106', three_epoch_id, two_epoch_id]:\n",
    "        values = ds.prompts[f'kortemeyer_{model}_answer'].value_counts()\n",
    "        if len(values) != ds.ways:\n",
    "            print(f'Dataset {i}, {ds.dataset} {ds.ways}way {ds.test_state}, on {model}, had the following value counts:')\n",
    "            print(values)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [['SCIENTSBANK'] * 6 + ['BEETLE'] * 4, ['2-way'] * 3 + ['3-way'] * 3 + ['2-way'] * 2 + ['3-way'] * 2, ['UA', 'UQ', 'UD'] * 2 + ['UA', 'UQ'] * 2]\n",
    "inds = ['FT-2_Epochs: GPT-3.5', 'FT-3_Epochs: GPT-3.5',  'GPT-3.5', 'GPT-4']\n",
    "\n",
    "\n",
    "\n",
    "order_testing_sets = testing_sets[2:5] + testing_sets[7:] + testing_sets[:2] + testing_sets[5:7]\n",
    "\n",
    "\n",
    "data = [\n",
    "    [ds.model_f1_score(two_epoch_id, 'kortemeyer') for ds in order_testing_sets],\n",
    "    [ds.model_f1_score(three_epoch_id, 'kortemeyer') for ds in order_testing_sets],\n",
    "    [pd.NA, calc_f1_multi_df(testing_sets[2:5], 'gpt-3.5-turbo-1106', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[7:], 'gpt-3.5-turbo-1106', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[:2], 'gpt-3.5-turbo-1106', 'kortemeyer'), \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[5:7], 'gpt-3.5-turbo-1106', 'kortemeyer'), \n",
    "    ],\n",
    "    [pd.NA, calc_f1_multi_df(testing_sets[2:5], 'gpt-4', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[7:], 'gpt-4', 'kortemeyer'), pd.NA, \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[:2], 'gpt-4', 'kortemeyer'), \n",
    "     pd.NA, calc_f1_multi_df(testing_sets[5:7], 'gpt-4', 'kortemeyer'), \n",
    "    ],\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = pd.DataFrame(data=data, index=inds, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">SCIENTSBANK</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BEETLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"3\" halign=\"left\">3-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3-way</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT-2_Epochs: GPT-3.5</th>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.736301</td>\n",
       "      <td>0.717856</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.783151</td>\n",
       "      <td>0.707384</td>\n",
       "      <td>0.742991</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.705602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT-3_Epochs: GPT-3.5</th>\n",
       "      <td>0.767635</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.693975</td>\n",
       "      <td>0.765531</td>\n",
       "      <td>0.746544</td>\n",
       "      <td>0.724348</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.648045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.663121</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.644678</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.561480</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.583514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.758691</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.742158</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.681452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SCIENTSBANK                                          \\\n",
       "                           2-way                         3-way             \n",
       "                              UA        UQ        UD        UA        UQ   \n",
       "FT-2_Epochs: GPT-3.5    0.783133  0.736301  0.717856  0.796875  0.783151   \n",
       "FT-3_Epochs: GPT-3.5    0.767635  0.719449  0.693975  0.765531  0.746544   \n",
       "GPT-3.5                     <NA>  0.663121      <NA>      <NA>  0.644678   \n",
       "GPT-4                       <NA>  0.758691      <NA>      <NA>  0.742158   \n",
       "\n",
       "                                  BEETLE                                \n",
       "                                   2-way               3-way            \n",
       "                            UD        UA        UQ        UA        UQ  \n",
       "FT-2_Epochs: GPT-3.5  0.707384  0.742991  0.717029  0.712329  0.705602  \n",
       "FT-3_Epochs: GPT-3.5  0.724348  0.736318  0.631579  0.730769  0.648045  \n",
       "GPT-3.5                   <NA>      <NA>  0.561480      <NA>  0.583514  \n",
       "GPT-4                     <NA>      <NA>  0.644295      <NA>  0.681452  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_pickle('results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">SCIENTSBANK</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BEETLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"3\" halign=\"left\">3-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2-way</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3-way</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UD</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UA</th>\n",
       "      <th>UQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT-2_Epochs: GPT-3.5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT-3_Epochs: GPT-3.5</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.66</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.64</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.56</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.76</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.74</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.64</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SCIENTSBANK                               BEETLE        \\\n",
       "                           2-way             3-way              2-way         \n",
       "                              UA    UQ    UD    UA    UQ    UD     UA    UQ   \n",
       "FT-2_Epochs: GPT-3.5        0.78  0.74  0.72   0.8  0.78  0.71   0.74  0.72   \n",
       "FT-3_Epochs: GPT-3.5        0.77  0.72  0.69  0.77  0.75  0.72   0.74  0.63   \n",
       "GPT-3.5                     <NA>  0.66  <NA>  <NA>  0.64  <NA>   <NA>  0.56   \n",
       "GPT-4                       <NA>  0.76  <NA>  <NA>  0.74  <NA>   <NA>  0.64   \n",
       "\n",
       "                                  \n",
       "                     3-way        \n",
       "                        UA    UQ  \n",
       "FT-2_Epochs: GPT-3.5  0.71  0.71  \n",
       "FT-3_Epochs: GPT-3.5  0.73  0.65  \n",
       "GPT-3.5               <NA>  0.58  \n",
       "GPT-4                 <NA>  0.68  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_results = results.replace(pd.NA, 0).round(2).replace(0, pd.NA)\n",
    "rn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_client.fine_tuning.jobs.create(\n",
    "  training_file=training_file, \n",
    "  validation_file=valid_file,\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_msgs = []\n",
    "valid_msgs = []\n",
    "for tset in training_sets:\n",
    "    new_msgs = tset.tune_messages('kortemeyer')\n",
    "    train_msgs = train_msgs + new_msgs[len(new_msgs) // 10:]\n",
    "    valid_msgs = valid_msgs + new_msgs[:len(new_msgs) // 10]\n",
    "\n",
    "with jsonlines.open('semeval-kortemeyer-tuning-v1.jsonl', mode='w') as writer:\n",
    "        writer.write_all(train_msgs)\n",
    "with jsonlines.open('semeval-kortemeyer-valid-v1.jsonl', mode='w') as writer:\n",
    "        writer.write_all(valid_msgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASAG_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
